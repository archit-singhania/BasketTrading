{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07521f86-cfb7-486a-a8d9-2fcf3648f676",
   "metadata": {},
   "source": [
    "Rolling-window Walk-Forward Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a121e6c-2c8c-4d88-b203-e1b6e986b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d32c53-802c-4135-b5c0-2bf91cd60f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "\n",
    "prices = pd.read_csv(\"../data/basket_prices.csv\", index_col=0, parse_dates=True).ffill()\n",
    "tickers = list(prices.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528b2931-e69c-46ee-8faa-58da68a6575b",
   "metadata": {},
   "source": [
    "Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5b0c3c-1e4b-406a-a344-1b1a614453b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def johansen_weights(price_df, det_order=0, k_ar_diff=1):\n",
    "    \"\"\"\n",
    "    Compute first Johansen cointegrating vector and normalize it so sum(abs)=1.\n",
    "    Returns numpy array of weights (length = number of series).\n",
    "    \"\"\"\n",
    "    arr = price_df.values\n",
    "    jres = coint_johansen(arr, det_order=det_order, k_ar_diff=k_ar_diff)\n",
    "    vec = jres.evec[:, 0]\n",
    "    w = vec / np.sum(np.abs(vec))\n",
    "    return w\n",
    "\n",
    "def construct_spread(price_df, weights):\n",
    "    \"\"\"Linear spread series = prices dot weights (returns pd.Series aligned with price_df.index).\"\"\"\n",
    "    s = price_df.dot(weights)\n",
    "    return pd.Series(s, index=price_df.index)\n",
    "\n",
    "def compute_zscore(series, lookback=20):\n",
    "    \"\"\"Rolling z-score (series - rolling_mean)/rolling_std.\"\"\"\n",
    "    mu = series.rolling(window=lookback, min_periods=5).mean()\n",
    "    sigma = series.rolling(window=lookback, min_periods=5).std()\n",
    "    return (series - mu) / sigma\n",
    "\n",
    "def half_life(series):\n",
    "    \"\"\"Estimate half-life of mean reversion via AR(1) on series.\"\"\"\n",
    "    s = series.dropna()\n",
    "    if len(s) < 10:\n",
    "        return np.nan\n",
    "    s_lag = s.shift(1).dropna()\n",
    "    delta = s.diff().dropna()\n",
    "    s_lag = s_lag.loc[delta.index]\n",
    "    X = sm.add_constant(s_lag.values)\n",
    "    model = sm.OLS(delta.values, X).fit()\n",
    "    b = model.params[1]\n",
    "    return -np.log(2) / b if b < 0 else np.nan\n",
    "\n",
    "def simple_strategy_pnl(spread, entry_z=2.0, exit_z=0.5, zlook=20, notional=1_000_000, tc=0.0):\n",
    "    \"\"\"\n",
    "    Simple zscore mean-reversion strategy on a spread series.\n",
    "    positions: 1 long spread, -1 short spread, 0 flat.\n",
    "    Returns DataFrame with position, daily_pnl, cum_pnl, daily_returns (pnl/notional).\n",
    "    tc = transaction cost per trade as fraction of notional (applied on entry & exit).\n",
    "    \"\"\"\n",
    "    z = compute_zscore(spread, lookback=zlook).dropna()\n",
    "    positions = pd.Series(0.0, index=z.index)\n",
    "    pos = 0.0\n",
    "    last_pos = 0.0\n",
    "    trades = 0\n",
    "\n",
    "    for t in z.index:\n",
    "        if pos == 0:\n",
    "            if z.loc[t] > entry_z:\n",
    "                pos = -1.0\n",
    "            elif z.loc[t] < -entry_z:\n",
    "                pos = 1.0\n",
    "        elif pos == 1.0:\n",
    "            if z.loc[t] >= -exit_z:\n",
    "                pos = 0.0\n",
    "        elif pos == -1.0:\n",
    "            if z.loc[t] <= exit_z:\n",
    "                pos = 0.0\n",
    "        positions.loc[t] = pos\n",
    "        if pos != last_pos:\n",
    "            trades += 1\n",
    "            last_pos = pos\n",
    "\n",
    "    positions = positions.ffill().fillna(0.0)\n",
    "    # Spread diff as absolute price change (P/L per unit of spread)\n",
    "    spread_diff = spread.reindex(positions.index).diff().fillna(0.0)\n",
    "    # pnl per day = position(t-1) * spread_diff(t)\n",
    "    pnl = positions.shift(1).fillna(0.0) * spread_diff\n",
    "\n",
    "    # Apply transaction cost: approximate cost = tc * notional on each trade (divided across day of trade)\n",
    "    # Here we subtract tc on days where position changes (entry or exit)\n",
    "    pos_changes = (positions != positions.shift(1)).astype(int)\n",
    "    pnl = pnl - pos_changes * (tc * notional)\n",
    "\n",
    "    cum_pnl = pnl.cumsum()\n",
    "    daily_returns = pnl / notional\n",
    "    return pd.DataFrame({\n",
    "        \"spread\": spread.reindex(positions.index),\n",
    "        \"zscore\": compute_zscore(spread, lookback=zlook).reindex(positions.index),\n",
    "        \"position\": positions,\n",
    "        \"pnl\": pnl,\n",
    "        \"cum_pnl\": cum_pnl,\n",
    "        \"daily_return\": daily_returns\n",
    "    })\n",
    "\n",
    "def performance_metrics(daily_returns, pnl_series=None):\n",
    "    \"\"\"Return dict of key metrics: annualized return, annualized volatility, Sharpe, max drawdown, total pnl.\"\"\"\n",
    "    if daily_returns.dropna().empty:\n",
    "        return {\"annual_return\": np.nan, \"annual_vol\": np.nan, \"sharpe\": np.nan, \"max_dd\": np.nan, \"total_pnl\": np.nan}\n",
    "    avg = daily_returns.mean()\n",
    "    std = daily_returns.std()\n",
    "    ann_ret = (1 + avg) ** 252 - 1 if avg > -1 else avg * 252  # approx if very small\n",
    "    ann_vol = std * np.sqrt(252)\n",
    "    sharpe = (avg / std) * np.sqrt(252) if std != 0 else np.nan\n",
    "    if pnl_series is not None:\n",
    "        running_max = pnl_series.cummax()\n",
    "        drawdown = (pnl_series - running_max)\n",
    "        max_dd = drawdown.min()\n",
    "        total_pnl = pnl_series.iloc[-1]\n",
    "    else:\n",
    "        max_dd = np.nan\n",
    "        total_pnl = np.nan\n",
    "    return {\"annual_return\": ann_ret, \"annual_vol\": ann_vol, \"sharpe\": sharpe, \"max_dd\": max_dd, \"total_pnl\": total_pnl}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e83f82-06dd-49e8-8b6b-f2bf0123a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling / walk-forward parameters\n",
    "\n",
    "train_window_days = 252 * 3    # 3 years training\n",
    "test_window_days = 252         # 1 year test\n",
    "step_days = 63                 # roll forward every 3 months\n",
    "zlook = 20\n",
    "entry_z = 2.0\n",
    "exit_z = 0.5\n",
    "transaction_cost = 0.0005      # 5 bps per trade on notional\n",
    "notional = 1_000_000           # scaling for pnl -> later use realistic sizing\n",
    "det_order = 0\n",
    "k_ar_diff = 1\n",
    "\n",
    "# build date index list for windows\n",
    "dates = prices.index\n",
    "start_idx = 0\n",
    "results_list = []\n",
    "window_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87b53b4-94b9-4507-87e6-efc5cbf24d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk-forward loop\n",
    "\n",
    "while True:\n",
    "    train_start = start_idx\n",
    "    train_end = train_start + train_window_days\n",
    "    test_end = train_end + test_window_days\n",
    "    # stop if test_end beyond data\n",
    "    if test_end >= len(dates):\n",
    "        break\n",
    "\n",
    "    train_slice = prices.iloc[train_start:train_end]\n",
    "    test_slice = prices.iloc[train_end:test_end]\n",
    "\n",
    "    # compute johansen weights on train slice\n",
    "    try:\n",
    "        w = johansen_weights(train_slice, det_order=det_order, k_ar_diff=k_ar_diff)\n",
    "    except Exception as e:\n",
    "        # fallback: equal weights if Johansen fails\n",
    "        print(f\"Johansen failed at window {window_idx}: {e}. Using equal weights.\")\n",
    "        w = np.ones(len(tickers)) / len(tickers)\n",
    "\n",
    "    # construct spread on test slice using train weights\n",
    "    spread_test = construct_spread(test_slice, w)\n",
    "\n",
    "    # run simple strategy on spread_test\n",
    "    strat_df = simple_strategy_pnl(spread_test, entry_z=entry_z, exit_z=exit_z,\n",
    "                                  zlook=zlook, notional=notional, tc=transaction_cost)\n",
    "\n",
    "    # metrics\n",
    "    metrics = performance_metrics(strat_df[\"daily_return\"], pnl_series=strat_df[\"cum_pnl\"])\n",
    "    metrics.update({\n",
    "        \"window_idx\": window_idx,\n",
    "        \"train_start\": dates[train_start].strftime(\"%Y-%m-%d\"),\n",
    "        \"train_end\": dates[train_end-1].strftime(\"%Y-%m-%d\"),\n",
    "        \"test_start\": dates[train_end].strftime(\"%Y-%m-%d\"),\n",
    "        \"test_end\": dates[test_end-1].strftime(\"%Y-%m-%d\"),\n",
    "        \"weights\": w\n",
    "    })\n",
    "\n",
    "    results_list.append(metrics)\n",
    "\n",
    "    # optional: save test period pnl to file for later aggregation/plotting\n",
    "    out_file = f\"../results/test_pnl_window_{window_idx}.csv\"\n",
    "    strat_df.to_csv(out_file)\n",
    "\n",
    "    # advance window\n",
    "    start_idx += step_days\n",
    "    window_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be0e409-0435-410b-9db9-0b75aa6b0a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk-forward summary saved to ../results/walkforward_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# aggregate results\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(\"../results/walkforward_summary.csv\", index=False)\n",
    "print(\"Walk-forward summary saved to ../results/walkforward_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e082e-3d3e-4dfe-92a4-85c247c9daaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect aggregated results & plots\n",
    "results_df = pd.read_csv(\"../results/walkforward_summary.csv\")\n",
    "display(results_df[[\"window_idx\",\"train_start\",\"train_end\",\"test_start\",\"test_end\",\"sharpe\",\"annual_return\",\"annual_vol\",\"max_dd\",\"total_pnl\"]])\n",
    "\n",
    "# Quick summary stats across windows\n",
    "print(\"Average Sharpe across test windows:\", results_df[\"sharpe\"].mean())\n",
    "print(\"Median Sharpe across test windows:\", results_df[\"sharpe\"].median())\n",
    "\n",
    "# Plot total_pnl across windows\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(results_df[\"window_idx\"], results_df[\"total_pnl\"])\n",
    "plt.xlabel(\"Window #\")\n",
    "plt.ylabel(\"Total PnL (test period)\")\n",
    "plt.title(\"Total PnL per Test Window\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
